# -*- coding: utf-8 -*-
"""AI_Kurma Ajwa Medjool

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aKJu-7xvLJKHf68gzfGt7RcrjW3OMzvy """

# Menghindari kekacauan output
import warnings
warnings.filterwarnings('ignore')

import pandas as pd # Untuk manipulasi dan analisis data
import numpy as np # Untuk penghitungan numerikal
import matplotlib.pyplot as plt # Untuk membuat plot (visualisasi data)

from sklearn.metrics import accuracy_score, f1_score, classification_report


# Import dataset dengan bentuk tabel/tabular
# Mount atau menyambungkan drive kelompok

from google.colab import drive
drive.mount('/content/drive')

# Csv secara alami membaca file yang digunakan
data = pd.read_csv('/content/drive/MyDrive/tubes/pengantar AI/AjwaOrMejdool.csv', sep=';')
data.columns = ['Date Length (cm)', 'Date Diameter (cm)', 'Date Weight (g)', 'Pit Length (cm)', 'Calories (Kcal)', 'Color', 'Class']
dataset = pd.DataFrame(data, columns=data.columns)
dataset


# Mengubah nilai pada kolom 'Color' dan 'Class' menjadi 0 dan 1
dataset['Color'] = dataset['Color'].apply(lambda x: 0.0 if x == 'Black' else 1.0)
dataset['Class'] = dataset['Class'].apply(lambda x: 0.0 if x == 'Ajwa' else 1.0)

dataset

# Encoding untuk mengubah data kategorikal menjadi data numerikal
dataset = pd.get_dummies(dataset)
dataset

# Cek apakah ada data yang null atau NaN
dataset.isna().sum()


# Memisahkan data variabel fitur dengan target
# Access data
X = dataset.drop(columns=['Class']) # Fitur untuk peng-klasifikasian (selain kelas)
y = dataset['Class'] # Target peng-klasifikasian kelas

# melihat sebaran data
# Before scalling
X.plot(kind='box')

# Melihat persebaran data berdasarkan class
from collections import Counter
target = y.values
counter = Counter(target)
for k,v in counter.items():
  per = v / len(target) *100
  print('Class=%s, Count=%d, Percentage=%.3f%%' % (k,v,per))


# standard scaller
((X-X.mean())/X.std()).plot(kind='box')

# robust scalling
((X - X.median())/(X.quantile(0.75)-X.quantile(0.25))).plot(kind='box')

# min max scaller
((X-X.min())/(X.max()-X.min())).plot(kind='box')

X.info() # menampilkan fitur-fitur yang ada (x)

X.describe() # menampilkan perhitungan data

X.head() # menampilkan 5 data fitur teratas

y.head() # menampilkan 5 data target teratas

# Mengacak data.
# Pengacakan ini dilakukan agar program dapat belajar dari data yang bervariasi, sehingga model menjadi lebih general dan tidak hanya terpaku pada pola urutan data awal.
X = X.sample(frac=1, random_state=42).reset_index(drop=True) # sample acak frac = 1, ambil semua dataset
y = y.sample(frac=1, random_state=42).reset_index(drop=True)

X

# Menampilkan data target setelah diacak
y

# Data Splitting
# K-Fold Processing (melakukan split data menjadi data train dan data testing menggunakan K-Fold)

num_of_fold = 3 #parameter k pada K-Fold, mau menjadi berapa fold? dibagi menjadi 3
num_per_fold = len(X) // num_of_fold #banyaknya data tiap fold

fold_split_index=[]
for i in range(num_of_fold):
  start_index = num_per_fold * i #definisikan index awal data validasi fold ke-i
  end_index = start_index + num_per_fold #definisikan index akhir data validasi fold ke-i
  val_index = np.arange(start_index, end_index) #definisi index data validasi(seluruh index di fold itu)

  print(val_index)

  #menjadikan index selain data validasi sebagai index data train
  mask = ~np.isin(X.index, val_index)
  train_index = X.index[mask]

  print(train_index)

  fold_split_index.append((train_index, val_index))

for train_index, val_index in fold_split_index:
  print(f'val start index: {val_index.min()}')

# Experiment Settings
# Write your code
class KNNClassifier:
  def __init__(self, n_neighbors=5): #berisi atribut-atribut dari suatu kelas
    self.n_neighbors = n_neighbors
    self.X_train = None
    self.y_train = None

  def fit(self, X, y): #digunakan untuk training
    self.X_train = X
    self.y_train = y

  def predict(self, X): #digunakan untuk prediksinya, udah selesai modelnya belajar, lalu prediksinya bekerja
    y_pred = [self._predict_one(x) for x in X]
    return np.array(y_pred)

  def _predict_one(self, X):
    distance = np.linalg.norm(self.X_train - X, axis = 1)
    nearest_indices = distance.argsort()[:self.n_neighbors]
    nearest_labels = self.y_train[nearest_indices]

    #pastikan nearest_labelnya adalah array 1 dimensi
    nearest_labels = np.array(nearest_labels).astype(int).flatten()
    most_common = np.bincount(nearest_labels).argmax()
    return most_common

#Tunning

tunning_log_f1 = []
tunning_log_akurasi = []
for i in range(1, 21):
  model = KNNClassifier(n_neighbors = i)

  total_akurasi = 0
  total_f1 = 0

  for i, (train_index, test_index) in enumerate(fold_split_index): #loop setiap fold dari 1 ke 5
      X_train_fold = X.iloc[train_index].reset_index(drop = True)
      y_train_fold = y.iloc[train_index].reset_index(drop = True)
      X_test_fold = X.iloc[test_index].reset_index(drop = True)
      y_test_fold = y.iloc[test_index].reset_index(drop = True)

      model.fit(X_train_fold.values, y_train_fold.values)
      y_pred = model.predict(X_test_fold.values)

      f1 = f1_score(y_test_fold, y_pred, average = "macro") * 100
      akurasi = accuracy_score(y_test_fold, y_pred) * 100

      total_f1 += f1
      total_akurasi += akurasi

  tunning_log_f1.append(total_f1 / num_of_fold)
  tunning_log_akurasi.append(total_akurasi / num_of_fold)

plt.subplot(111)
plt.suptitle('perbandingan performa hyperparameter')
plt.plot(tunning_log_f1)
plt.plot(tunning_log_akurasi)
plt.legend(['f1', 'akurasi'])
plt.xlabel('tetangga')
plt.xticks(labels=np.arange(1,21), ticks=np.arange(0,20))
plt.ylabel('performa dalam %')


model = KNNClassifier(n_neighbors=3)

print("EVALUASI KNN TERHADAP DATA TRAINING UNTUK N = 3")
total_akurasi = 0
total_f1 = 0

for i, (train_index, test_index) in enumerate(fold_split_index):
  X_train_fold = X.iloc[train_index].reset_index(drop=True)
  y_train_fold = y.iloc[train_index].reset_index(drop=True)
  X_test_fold = X.iloc[test_index].reset_index(drop=True)
  y_test_fold = y.iloc[test_index].reset_index(drop=True)

  model.fit(X_train_fold.values, y_train_fold.values)
  y_pred = model.predict(X_train_fold.values)

  f1 = f1_score(y_train_fold, y_pred, average = "macro") * 100
  akurasi = accuracy_score(y_train_fold, y_pred) * 100

  total_f1 += f1
  total_akurasi += akurasi

  print(f'Akurasi fold ke-{i+1}\t: {akurasi}%')
  print(f'Skor F1 fold ke-{i+1}\t: {f1}%')
  print()

print("\nRata-rata f1 : ", total_f1 / num_of_fold, "%")
print('Rata-rata Akurasi :', total_akurasi / num_of_fold, "%")
print()

model = KNNClassifier(n_neighbors=8)

print("EVALUASI KNN TERHADAP DATA TRAINING N = 8")
total_akurasi = 0
total_f1 = 0

for i, (train_index, test_index) in enumerate(fold_split_index):
  X_train_fold = X.iloc[train_index].reset_index(drop=True)
  y_train_fold = y.iloc[train_index].reset_index(drop=True)
  X_test_fold = X.iloc[test_index].reset_index(drop=True)
  y_test_fold = y.iloc[test_index].reset_index(drop=True)

  model.fit(X_train_fold.values, y_train_fold.values)
  y_pred = model.predict(X_train_fold.values)

  f1 = f1_score(y_train_fold, y_pred, average = "macro") * 100
  akurasi = accuracy_score(y_train_fold, y_pred) * 100

  total_f1 += f1
  total_akurasi += akurasi

  print(f'Akurasi fold ke-{i+1}\t: {akurasi}%')
  print(f'Skor F1 fold ke-{i+1}\t: {f1}%')
  print()

print("\nRata-rata f1 : ", total_f1 / num_of_fold, "%")
print('Rata-rata Akurasi :', total_akurasi / num_of_fold, "%")
print()


model = KNNClassifier(n_neighbors=3)

print("EVALUASI KNN TERHADAP DATA TESTING N = 3")
total_akurasi = 0
total_f1 = 0

for i, (train_index, test_index) in enumerate(fold_split_index):
  X_train_fold = X.iloc[train_index].reset_index(drop=True)
  y_train_fold = y.iloc[train_index].reset_index(drop=True)
  X_test_fold = X.iloc[test_index].reset_index(drop=True)
  y_test_fold = y.iloc[test_index].reset_index(drop=True)

  model.fit(X_train_fold.values, y_train_fold.values)
  y_pred = model.predict(X_test_fold.values)

  f1 = f1_score(y_test_fold, y_pred, average = "macro") * 100
  akurasi = accuracy_score(y_test_fold, y_pred) * 100

  total_f1 += f1
  total_akurasi += akurasi

  print(f'Akurasi fold ke-{i+1}\t: {akurasi}%')
  print(f'Skor F1 fold ke-{i+1}\t: {f1}%')
  print()

print("\nRata-rata f1 : ", total_f1 / num_of_fold, "%")
print('Rata-rata Akurasi :', total_akurasi / num_of_fold, "%")
print()

model = KNNClassifier(n_neighbors=8)

print("EVALUASI KNN TERHADAP DATA TESTING N = 8")
total_akurasi = 0
total_f1 = 0

for i, (train_index, test_index) in enumerate(fold_split_index):
  X_train_fold = X.iloc[train_index].reset_index(drop=True)
  y_train_fold = y.iloc[train_index].reset_index(drop=True)
  X_test_fold = X.iloc[test_index].reset_index(drop=True)
  y_test_fold = y.iloc[test_index].reset_index(drop=True)

  model.fit(X_train_fold.values, y_train_fold.values)
  y_pred = model.predict(X_test_fold.values)

  f1 = f1_score(y_test_fold, y_pred, average = "macro") * 100
  akurasi = accuracy_score(y_test_fold, y_pred) * 100

  total_f1 += f1
  total_akurasi += akurasi

  print(f'Akurasi fold ke-{i+1}\t: {akurasi}%')
  print(f'Skor F1 fold ke-{i+1}\t: {f1}%')
  print()


print("\nRata-rata f1 : ", total_f1 / num_of_fold, "%")
print('Rata-rata Akurasi :', total_akurasi / num_of_fold, "%")


from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # Imports necessary modules
model = KNNClassifier(n_neighbors=3)

total_akurasi = 0
total_f1 = 0
for i, (train_index, val_index) in enumerate(fold_split_index):  #looping untuk setiap fold dari fold 1 sampai 3
  X_train_fold = X.iloc[train_index].reset_index(drop=True) #data train di fold 1 dst
  y_train_fold = y.iloc[train_index].reset_index(drop=True)

  X_val_fold = X.iloc[val_index].reset_index(drop=True) #data uji di fold 1 dst
  y_val_fold = y.iloc[val_index].reset_index(drop=True)

  model.fit(X_train_fold.values, y_train_fold.values) #train model

  y_pred = model.predict(X_val_fold.values) #menghasilkan prediksi
  print('Confusion Matrix')
  ConfusionMatrixDisplay(confusion_matrix(y_val_fold, y_pred), display_labels=['Ajwa', 'Medjool']).plot()
